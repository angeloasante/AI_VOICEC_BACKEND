"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.MediaStreamHandler = void 0;
const ws_1 = __importDefault(require("ws"));
const events_1 = require("events");
const twilio_1 = __importDefault(require("twilio"));
const transcriber_js_1 = require("./transcriber.js");
const synthesizer_js_1 = require("./synthesizer.js");
const brain_js_1 = require("./brain.js");
const call_session_js_1 = require("./call-session.js");
const config_js_1 = require("../config.js");
// Initialize Twilio client for call management
const twilioClient = (0, twilio_1.default)(config_js_1.config.twilio.accountSid, config_js_1.config.twilio.authToken);
/**
 * Handles a single Twilio Media Stream WebSocket connection
 * Orchestrates the full voice pipeline: audio in â†’ transcription â†’ AI â†’ TTS â†’ audio out
 */
class MediaStreamHandler extends events_1.EventEmitter {
    ws;
    streamSid = null;
    callSid = null;
    transcriber = null;
    synthesizer = null;
    audioQueue = [];
    isSending = false;
    markCounter = 0;
    constructor(ws) {
        super();
        this.ws = ws;
        this.setupWebSocket();
    }
    /**
     * Set up WebSocket event handlers
     */
    setupWebSocket() {
        this.ws.on('message', async (data) => {
            try {
                const message = JSON.parse(data.toString());
                await this.handleMessage(message);
            }
            catch (error) {
                console.error('Error handling WebSocket message:', error);
            }
        });
        this.ws.on('close', () => {
            console.log('ðŸ“´ Twilio WebSocket closed');
            this.cleanup();
        });
        this.ws.on('error', (error) => {
            console.error('âŒ Twilio WebSocket error:', error);
            this.cleanup();
        });
    }
    /**
     * Handle incoming Twilio Media Stream messages
     */
    async handleMessage(message) {
        switch (message.event) {
            case 'connected':
                console.log('ðŸ”— Twilio Media Stream connected');
                break;
            case 'start':
                await this.handleStart(message);
                break;
            case 'media':
                this.handleMedia(message);
                break;
            case 'mark':
                this.handleMark(message);
                break;
            case 'stop':
                console.log('ðŸ›‘ Twilio Media Stream stopped');
                this.cleanup();
                break;
        }
    }
    /**
     * Handle stream start - initialize transcriber and send greeting
     */
    async handleStart(message) {
        if (!message.start)
            return;
        this.streamSid = message.start.streamSid;
        this.callSid = message.start.callSid;
        // Get caller phone from custom parameters (passed from webhook)
        const callerPhone = message.start.customParameters?.callerPhone;
        console.log(`ðŸ“ž Call started - SID: ${this.callSid}, Stream: ${this.streamSid}`);
        // Create session with caller phone for SMS capability
        (0, call_session_js_1.createSession)(this.callSid, this.streamSid, callerPhone);
        // Initialize components
        this.synthesizer = new synthesizer_js_1.Synthesizer(this.streamSid);
        this.transcriber = new transcriber_js_1.Transcriber(this.streamSid);
        // Set up transcriber events
        this.transcriber.on('transcript', async (result) => {
            await this.handleTranscript(result.transcript);
        });
        this.transcriber.on('interim', (result) => {
            // Barge-in detection: immediately stop AI speech when user starts talking
            // Only trigger on meaningful speech (not just "um", "uh", breathing noises)
            const transcript = result.transcript?.trim() || '';
            if (transcript.length > 3 && !/^(um+|uh+|ah+|oh+|hm+)$/i.test(transcript)) {
                this.handleBargeIn();
            }
        });
        this.transcriber.on('error', (error) => {
            console.error('ðŸŽ¤ Transcriber error:', error);
        });
        // Connect to Deepgram
        try {
            await this.transcriber.connect();
        }
        catch (error) {
            console.error('Failed to connect to Deepgram:', error);
            return;
        }
        // Send greeting
        const greeting = await (0, brain_js_1.generateGreeting)(this.streamSid);
        await this.speakResponse(greeting);
    }
    /**
     * Handle incoming audio from Twilio
     */
    handleMedia(message) {
        if (!message.media || !this.transcriber)
            return;
        // Decode base64 audio and send to transcriber
        const audioBuffer = Buffer.from(message.media.payload, 'base64');
        this.transcriber.sendAudio(audioBuffer);
    }
    /**
     * Handle mark events (audio playback completion)
     */
    handleMark(message) {
        // Mark indicates that a chunk of audio has finished playing
        // Only log significant marks to reduce noise
        const markName = message.mark?.name || '';
        if (markName.includes('end')) {
            console.log(`âœ“ Audio playback complete: ${markName}`);
        }
    }
    /**
     * Handle completed transcript - generate and speak response
     */
    async handleTranscript(transcript) {
        if (!this.streamSid)
            return;
        // Prevent overlapping responses
        if ((0, call_session_js_1.isProcessing)(this.streamSid)) {
            console.log('â³ Already processing, queuing transcript...');
            return;
        }
        (0, call_session_js_1.setProcessing)(this.streamSid, true);
        try {
            // Clear any queued audio (interrupt current speech)
            this.clearAudioQueue();
            // Generate AI response with streaming
            const result = await (0, brain_js_1.generateResponse)(this.streamSid, transcript, async (textChunk) => {
                // Synthesize and queue each text chunk
                await this.speakResponse(textChunk);
            });
            // Check if we should end the call after the response
            if (result.shouldEndCall && this.callSid) {
                console.log(`ðŸ‘‹ Call ending after goodbye - waiting for audio to finish...`);
                // Wait a bit for audio to play, then end the call
                setTimeout(async () => {
                    try {
                        if (this.callSid) {
                            console.log(`ðŸ“ž Ending call: ${this.callSid}`);
                            await twilioClient.calls(this.callSid).update({ status: 'completed' });
                            console.log(`âœ… Call ended successfully`);
                        }
                    }
                    catch (error) {
                        console.error('âŒ Error ending call:', error);
                    }
                }, 4000); // Wait 4 seconds for goodbye audio to play
            }
        }
        catch (error) {
            console.error('Error processing transcript:', error);
        }
        finally {
            (0, call_session_js_1.setProcessing)(this.streamSid, false);
        }
    }
    /**
     * Synthesize text and send audio to Twilio
     */
    async speakResponse(text) {
        if (!this.synthesizer || !this.streamSid)
            return;
        try {
            await this.synthesizer.synthesize(text, (audioChunk) => {
                this.queueAudio(audioChunk);
            });
            // Flush all audio after TTS completes for this text segment
            this.flushAudioQueue();
        }
        catch (error) {
            console.error('Error synthesizing speech:', error);
        }
    }
    /**
     * Queue audio chunk for sending to Twilio
     */
    queueAudio(audioBase64) {
        this.audioQueue.push(audioBase64);
        // Don't process immediately - let audio batch up
    }
    /**
     * Flush all queued audio to Twilio
     */
    flushAudioQueue() {
        if (this.audioQueue.length === 0)
            return;
        if (this.ws.readyState !== ws_1.default.OPEN)
            return;
        let chunksSent = 0;
        while (this.audioQueue.length > 0) {
            const audioChunk = this.audioQueue.shift();
            // Send media message to Twilio
            const mediaMessage = {
                event: 'media',
                streamSid: this.streamSid,
                media: {
                    payload: audioChunk,
                },
            };
            this.ws.send(JSON.stringify(mediaMessage));
            chunksSent++;
        }
        // Send ONE mark at the end to track when all audio finishes
        this.markCounter++;
        const markMessage = {
            event: 'mark',
            streamSid: this.streamSid,
            mark: {
                name: `response-end-${this.markCounter}`,
            },
        };
        this.ws.send(JSON.stringify(markMessage));
        console.log(`ðŸ“¤ Sent ${chunksSent} audio chunks to Twilio`);
    }
    /**
     * Process the audio queue and send to Twilio
     */
    processAudioQueue() {
        if (this.isSending || this.audioQueue.length === 0)
            return;
        if (this.ws.readyState !== ws_1.default.OPEN)
            return;
        this.isSending = true;
        while (this.audioQueue.length > 0) {
            const audioChunk = this.audioQueue.shift();
            // Send media message to Twilio
            const mediaMessage = {
                event: 'media',
                streamSid: this.streamSid,
                media: {
                    payload: audioChunk,
                },
            };
            this.ws.send(JSON.stringify(mediaMessage));
        }
        // Send a mark to track when audio finishes playing
        this.markCounter++;
        const markMessage = {
            event: 'mark',
            streamSid: this.streamSid,
            mark: {
                name: `response-${this.markCounter}`,
            },
        };
        this.ws.send(JSON.stringify(markMessage));
        this.isSending = false;
    }
    /**
     * Clear the audio queue (for interruption handling)
     */
    clearAudioQueue() {
        this.audioQueue = [];
        // Send clear message to Twilio to stop current playback
        if (this.ws.readyState === ws_1.default.OPEN && this.streamSid) {
            const clearMessage = {
                event: 'clear',
                streamSid: this.streamSid,
            };
            this.ws.send(JSON.stringify(clearMessage));
        }
    }
    /**
     * Handle barge-in: user started speaking, stop AI immediately
     */
    handleBargeIn() {
        // Only interrupt if we're currently speaking (have queued audio)
        if (this.audioQueue.length > 0 || this.isSending) {
            console.log('ðŸ›‘ Barge-in detected - stopping AI speech');
            this.clearAudioQueue();
        }
    }
    /**
     * Clean up resources
     */
    cleanup() {
        if (this.transcriber) {
            this.transcriber.close();
            this.transcriber = null;
        }
        if (this.streamSid) {
            (0, call_session_js_1.endSession)(this.streamSid);
        }
        this.audioQueue = [];
        this.emit('ended');
    }
}
exports.MediaStreamHandler = MediaStreamHandler;
//# sourceMappingURL=media-stream.js.map